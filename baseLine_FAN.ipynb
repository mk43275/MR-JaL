{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/asyncio/base_events.py\", line 595, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/asyncio/base_events.py\", line 1881, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/3y/2jj6w99n11g766vg19kpr73h0000gn/T/ipykernel_4755/4281350836.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403226260/work/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "#Mojo of reproducibility\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed):\n",
    "  #PyTorch\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  #Numpy\n",
    "  np.random.seed(seed)\n",
    "  #Python_random\n",
    "  random.seed(seed)\n",
    "  #CuDNN (when using CUDA)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fan import FANLayer\n",
    "\n",
    "class FAN_Classifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, dropout_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define a list of layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Define the first layer\n",
    "        self.layers.append(nn.Linear(173, hidden_size))\n",
    "        \n",
    "        # Define the intermediate hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(FANLayer(hidden_size, hidden_size))\n",
    "        \n",
    "        # Final layer to output\n",
    "        self.emo_output_layer = nn.Linear(hidden_size, 6)\n",
    "        self.strength_output_layer = nn.Linear(hidden_size, 3)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Pass through hidden layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x = self.dropout(x)\n",
    "        # Output layers\n",
    "        emo_output = self.emo_output_layer(x)\n",
    "        strength_output = self.strength_output_layer(x)\n",
    "                \n",
    "        return emo_output, strength_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class voiceDataset(Dataset):\n",
    "    def __init__(self, features, emotionLabels, strengthLabels):\n",
    "        self.features = features\n",
    "        self.emotionLabels = emotionLabels\n",
    "        self.strengthLabels = strengthLabels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'features':self.features[idx], \n",
    "                'emotionLabel':self.emotionLabels[idx], \n",
    "                'strengthLabel':self.strengthLabels[idx]\n",
    "        }   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('featuresAndLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut corresponding columns of df into features and labels\n",
    "# Turn them into tensors\n",
    "features = df.iloc[:, 1:174].values\n",
    "features = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "emotionLabels = df.iloc[:,174:180].values\n",
    "emotionLabels = torch.tensor(emotionLabels, dtype=torch.float32)\n",
    "\n",
    "strengthLabels = df.iloc[:,180:183].values\n",
    "strengthLabels = torch.tensor(strengthLabels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5953 372 1117\n",
      "5953 372 372 1117\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "# train, validate, test = 8:1:1\n",
    "train_size = int(0.8 * len(df))\n",
    "val_size = int(0.05 * len(df))\n",
    "test_size = len(df) - train_size - val_size\n",
    "\n",
    "print(train_size, val_size, test_size)\n",
    "\n",
    "train_dataset = voiceDataset(features[:train_size], \n",
    "                             emotionLabels[:train_size], \n",
    "                             strengthLabels[:train_size])\n",
    "\n",
    "validate_dataset_1 = voiceDataset(features[train_size:train_size + val_size],\n",
    "                                emotionLabels[train_size:train_size + val_size], \n",
    "                                strengthLabels[train_size:train_size + val_size])\n",
    "\n",
    "validate_dataset_2 = voiceDataset(features[train_size + val_size:train_size + 2 * val_size],\n",
    "                                emotionLabels[train_size + val_size:train_size + 2 * val_size], \n",
    "                                strengthLabels[train_size + val_size:train_size + 2 * val_size])\n",
    "\n",
    "test_dataset = voiceDataset(features[train_size + val_size:],\n",
    "                            emotionLabels[train_size + val_size:], \n",
    "                            strengthLabels[train_size + val_size:])\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(len(train_dataset),len(validate_dataset_1), len(validate_dataset_2), len(test_dataset))\n",
    "\n",
    "# Create dataLoader\n",
    "trainDataLoader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "validationDataLoader_1 = DataLoader(validate_dataset_1,batch_size=128)\n",
    "validationDataLoader_2 = DataLoader(validate_dataset_2,batch_size=128)\n",
    "testDataLoader = DataLoader(test_dataset,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Define the trainer & validator function\n",
    "def train_validate_model(hidden_size = 0,\n",
    "                         num_layers = 0,\n",
    "                         dropout_rate = 0, \n",
    "                         trainDataLoader = None, \n",
    "                         validationDataLoader = None,\n",
    "                         num_epochs = 0, \n",
    "                         learning_rate = 0,\n",
    "                        save = False):\n",
    "\n",
    "    set_seed(42)\n",
    "\n",
    "    #Get the GPU as a device if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    #Instantiate the model\n",
    "    model = FAN_Classifier(hidden_size = hidden_size,\n",
    "                           num_layers = num_layers,\n",
    "                           dropout_rate = dropout_rate)\n",
    "\n",
    "    # Moving the model to GPU if available\n",
    "    model.to(device)\n",
    "\n",
    "    #Prepare the optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #Prepare the error function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    #Prepare the scheduler\n",
    "    #Reduce the learning rate by 0.1 if the validation loss does not decrease for 3 epochs\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    #Prepare the DataLoader\n",
    "    train_data_loader = trainDataLoader\n",
    "    validation_data_loader = validationDataLoader\n",
    "\n",
    "    #Placeholder for minimum validation loss\n",
    "    min_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        #set the model to training mode\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0 #Placeholder for training loss per epoch\n",
    "        for batch in train_data_loader:\n",
    "            feature = batch['features'].to(device)\n",
    "            emotionLabel = batch['emotionLabel'].to(device)\n",
    "            strengthLabel = batch['strengthLabel'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            emotionOutput, strengthOutput = model(feature)\n",
    "            #Calculate the loss for emotion head\n",
    "            emo_loss = criterion(emotionOutput, emotionLabel)\n",
    "            #Calculate the loss for strength head\n",
    "            strength_loss = criterion(strengthOutput, strengthLabel)\n",
    "            #Combine two losses to make a total loss. \n",
    "            #Put more weight on the emotion loss (7:3). Detecting emotion is more critical\n",
    "            loss = 0.7*emo_loss + 0.3*strength_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        #Validate the model\n",
    "        model.eval() #Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            total_samples = 0 #Total output for accuracy calculation\n",
    "            emoCorrect = 0 #Amount of correct prediction for accuracy calculation\n",
    "            strengthCorrect = 0\n",
    "            total_val_loss = 0 #Placeholder for validation loss per epoch\n",
    "            \n",
    "            for batch in validation_data_loader:\n",
    "                feature = batch['features'].to(device)\n",
    "                emotionLabel = batch['emotionLabel'].to(device)\n",
    "                strengthLabel = batch['strengthLabel'].to(device)\n",
    "                #Forward pass\n",
    "                emotionOutput, strengthOutput = model(feature)\n",
    "                emo_loss = criterion(emotionOutput, emotionLabel)\n",
    "                strength_loss = criterion(strengthOutput, strengthLabel )\n",
    "                total_val_loss += 0.7*emo_loss + 0.3*strength_loss\n",
    "                \n",
    "                # Get predicted emotion class & target emotion class\n",
    "                emo_predicted = torch.argmax(emotionOutput, dim=1)\n",
    "                emo_target = torch.argmax(emotionLabel, dim=1)\n",
    "                \n",
    "                # Get predicted strength class & target emotion class\n",
    "                strength_predicted = torch.argmax(strengthOutput,dim=1)\n",
    "                strength_target = torch.argmax(strengthLabel, dim=1 )\n",
    "                \n",
    "                emoCorrect += (emo_predicted == emo_target).sum().item()\n",
    "                strengthCorrect += (strength_predicted ==strength_target).sum().item()\n",
    "                \n",
    "                #Get total number of samples per epoch\n",
    "                total_samples += emotionLabel.size(0)\n",
    "\n",
    "            emo_accuracy = emoCorrect / total_samples\n",
    "            strength_accuracy = strengthCorrect / total_samples\n",
    "\n",
    "\n",
    "            #Print out the validation loss and accuracy per epoch\n",
    "            # print(f\"Epoch {epoch+1}/{num_epochs} | Training Loss: {total_loss:.4f}, Validation Loss: {total_val_loss:.4f}, Accuracy (Emotion): {emo_accuracy:.4f}, Accuracy (Strength): {strength_accuracy}\")\n",
    "\n",
    "            #pass the validation loss to the scheduler\n",
    "            scheduler.step(total_val_loss)\n",
    "\n",
    "        #If fineTuning = False, save the model with the lowest validation loss\n",
    "        #Save the first epoch model just in case\n",
    "\n",
    "            if epoch == 0:\n",
    "                min_val_loss = total_val_loss #Instantiate the min_val_loss at the first epoch\n",
    "                if save == True:\n",
    "                    torch.save(model.state_dict(), 'bestFAN.pth')\n",
    "            #Save the model if the validation loss is the lowest\n",
    "            elif total_val_loss < min_val_loss:\n",
    "                min_val_loss = total_val_loss\n",
    "                if save == True:\n",
    "                    torch.save(model.state_dict(), 'bestFAN.pth')\n",
    "                    print(f\"Model saved after Epoch: {epoch+1}\")\n",
    "                        \n",
    "    #Return the minimum validation loss for hyperparameter tuning\n",
    "    return min_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    set_seed(42)\n",
    "\n",
    "    #Define the hyperparameters to be tuned\n",
    "    #Dimension of the hidden layer (Make it divisible by 4 to avoid shape mismatch)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 52, 100, step=4)\n",
    "    #Number of layers\n",
    "    num_layers = trial.suggest_int('num_layers', 5, 15)\n",
    "    #Dropout rate for the final feedforward network [0.1, 0.5]\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    #Number of epochs [10, 30]\n",
    "    num_epochs = trial.suggest_int('num_epochs', 10, 30)\n",
    "    #Learning rate for the optimizer [1e-5, 1e-3]\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3)\n",
    "\n",
    "    result = train_validate_model(hidden_size = hidden_size,\n",
    "                                  num_layers = num_layers,\n",
    "                                  dropout_rate = dropout_rate,\n",
    "                                  trainDataLoader = trainDataLoader,\n",
    "                                  validationDataLoader = validationDataLoader_1,\n",
    "                                  num_epochs = num_epochs,\n",
    "                                  learning_rate = learning_rate,\n",
    "                                  save = False\n",
    "                                  )\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 18:31:40,217] A new study created in memory with name: no-name-8f923894-36b6-4c9c-b82f-d3090916feb3\n",
      "/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "[I 2025-04-07 18:31:43,730] Trial 0 finished with value: 4.056650161743164 and parameters: {'hidden_size': 56, 'num_layers': 6, 'dropout_rate': 0.26965837296449824, 'num_epochs': 26, 'learning_rate': 0.0007554774751746104}. Best is trial 0 with value: 4.056650161743164.\n",
      "[I 2025-04-07 18:31:47,447] Trial 1 finished with value: 4.060760498046875 and parameters: {'hidden_size': 84, 'num_layers': 8, 'dropout_rate': 0.237863290934139, 'num_epochs': 20, 'learning_rate': 0.0006137881479485964}. Best is trial 0 with value: 4.056650161743164.\n",
      "[I 2025-04-07 18:31:50,421] Trial 2 finished with value: 4.077528476715088 and parameters: {'hidden_size': 68, 'num_layers': 9, 'dropout_rate': 0.40853717145636403, 'num_epochs': 15, 'learning_rate': 0.0006983279205018003}. Best is trial 0 with value: 4.056650161743164.\n",
      "[I 2025-04-07 18:31:55,186] Trial 3 finished with value: 4.0658111572265625 and parameters: {'hidden_size': 60, 'num_layers': 10, 'dropout_rate': 0.35352273077467933, 'num_epochs': 28, 'learning_rate': 0.0006999342869694663}. Best is trial 0 with value: 4.056650161743164.\n",
      "[I 2025-04-07 18:31:57,448] Trial 4 finished with value: 4.059988975524902 and parameters: {'hidden_size': 52, 'num_layers': 15, 'dropout_rate': 0.19272871258390825, 'num_epochs': 10, 'learning_rate': 0.00033891233828614006}. Best is trial 0 with value: 4.056650161743164.\n",
      "[I 2025-04-07 18:32:00,185] Trial 5 finished with value: 4.692400932312012 and parameters: {'hidden_size': 100, 'num_layers': 7, 'dropout_rate': 0.4511003330425536, 'num_epochs': 16, 'learning_rate': 0.0001220000601363326}. Best is trial 0 with value: 4.056650161743164.\n",
      "[I 2025-04-07 18:32:02,474] Trial 6 finished with value: 4.086750507354736 and parameters: {'hidden_size': 84, 'num_layers': 5, 'dropout_rate': 0.20961867932314704, 'num_epochs': 21, 'learning_rate': 0.00028944305665234917}. Best is trial 0 with value: 4.056650161743164.\n",
      "[I 2025-04-07 18:32:04,599] Trial 7 finished with value: 4.058734893798828 and parameters: {'hidden_size': 88, 'num_layers': 6, 'dropout_rate': 0.3983431134196375, 'num_epochs': 16, 'learning_rate': 0.0005286880136370416}. Best is trial 0 with value: 4.056650161743164.\n",
      "[I 2025-04-07 18:32:09,978] Trial 8 finished with value: 4.054073810577393 and parameters: {'hidden_size': 64, 'num_layers': 15, 'dropout_rate': 0.10072023938177779, 'num_epochs': 24, 'learning_rate': 0.00022016769462055293}. Best is trial 8 with value: 4.054073810577393.\n",
      "[I 2025-04-07 18:32:11,978] Trial 9 finished with value: 4.169633865356445 and parameters: {'hidden_size': 92, 'num_layers': 9, 'dropout_rate': 0.47935776943159064, 'num_epochs': 10, 'learning_rate': 0.00032772597705195205}. Best is trial 8 with value: 4.054073810577393.\n",
      "[I 2025-04-07 18:32:19,987] Trial 10 finished with value: 4.130719184875488 and parameters: {'hidden_size': 72, 'num_layers': 15, 'dropout_rate': 0.10579689344463034, 'num_epochs': 30, 'learning_rate': 1.4274648178956464e-05}. Best is trial 8 with value: 4.054073810577393.\n",
      "[I 2025-04-07 18:32:24,976] Trial 11 finished with value: 4.047433853149414 and parameters: {'hidden_size': 60, 'num_layers': 12, 'dropout_rate': 0.12263501269108412, 'num_epochs': 25, 'learning_rate': 0.000925751759175296}. Best is trial 11 with value: 4.047433853149414.\n",
      "[I 2025-04-07 18:32:29,867] Trial 12 finished with value: 4.052523136138916 and parameters: {'hidden_size': 64, 'num_layers': 13, 'dropout_rate': 0.10805769715817243, 'num_epochs': 24, 'learning_rate': 0.0008752030124879707}. Best is trial 11 with value: 4.047433853149414.\n",
      "[I 2025-04-07 18:32:35,234] Trial 13 finished with value: 4.033079147338867 and parameters: {'hidden_size': 72, 'num_layers': 12, 'dropout_rate': 0.15792379016597063, 'num_epochs': 23, 'learning_rate': 0.0009947558424523051}. Best is trial 13 with value: 4.033079147338867.\n",
      "[I 2025-04-07 18:32:40,175] Trial 14 finished with value: 4.050900936126709 and parameters: {'hidden_size': 76, 'num_layers': 12, 'dropout_rate': 0.17141990294628348, 'num_epochs': 21, 'learning_rate': 0.000984400168043371}. Best is trial 13 with value: 4.033079147338867.\n",
      "[I 2025-04-07 18:32:45,831] Trial 15 finished with value: 4.054269790649414 and parameters: {'hidden_size': 76, 'num_layers': 12, 'dropout_rate': 0.15703964646955443, 'num_epochs': 24, 'learning_rate': 0.000965000246499368}. Best is trial 13 with value: 4.033079147338867.\n",
      "[I 2025-04-07 18:32:51,150] Trial 16 finished with value: 4.055899620056152 and parameters: {'hidden_size': 52, 'num_layers': 13, 'dropout_rate': 0.31087904516105636, 'num_epochs': 27, 'learning_rate': 0.0008670815780412833}. Best is trial 13 with value: 4.033079147338867.\n",
      "[I 2025-04-07 18:32:54,653] Trial 17 finished with value: 4.063257694244385 and parameters: {'hidden_size': 60, 'num_layers': 11, 'dropout_rate': 0.14855748362423185, 'num_epochs': 19, 'learning_rate': 0.0008073800051468206}. Best is trial 13 with value: 4.033079147338867.\n",
      "[I 2025-04-07 18:33:01,953] Trial 18 finished with value: 4.049860954284668 and parameters: {'hidden_size': 72, 'num_layers': 13, 'dropout_rate': 0.24144364869408053, 'num_epochs': 30, 'learning_rate': 0.0004441712794511493}. Best is trial 13 with value: 4.033079147338867.\n",
      "[I 2025-04-07 18:33:06,542] Trial 19 finished with value: 4.052002429962158 and parameters: {'hidden_size': 68, 'num_layers': 11, 'dropout_rate': 0.30198274380221035, 'num_epochs': 23, 'learning_rate': 0.0009092903995247541}. Best is trial 13 with value: 4.033079147338867.\n",
      "[I 2025-04-07 18:33:13,797] Trial 20 finished with value: 4.048995494842529 and parameters: {'hidden_size': 80, 'num_layers': 14, 'dropout_rate': 0.14174523371165265, 'num_epochs': 26, 'learning_rate': 0.0009998809707654605}. Best is trial 13 with value: 4.033079147338867.\n",
      "[I 2025-04-07 18:33:21,797] Trial 21 finished with value: 4.055714130401611 and parameters: {'hidden_size': 80, 'num_layers': 14, 'dropout_rate': 0.13795290875269284, 'num_epochs': 26, 'learning_rate': 0.0009972620425810674}. Best is trial 13 with value: 4.033079147338867.\n",
      "[I 2025-04-07 18:33:28,595] Trial 22 finished with value: 4.050234794616699 and parameters: {'hidden_size': 76, 'num_layers': 12, 'dropout_rate': 0.193923197684627, 'num_epochs': 28, 'learning_rate': 0.0008155806035597319}. Best is trial 13 with value: 4.033079147338867.\n",
      "[I 2025-04-07 18:33:35,756] Trial 23 finished with value: 4.046204090118408 and parameters: {'hidden_size': 92, 'num_layers': 14, 'dropout_rate': 0.13427224428717766, 'num_epochs': 22, 'learning_rate': 0.0009250523635305475}. Best is trial 13 with value: 4.033079147338867.\n",
      "[I 2025-04-07 18:33:40,160] Trial 24 finished with value: 4.052295207977295 and parameters: {'hidden_size': 96, 'num_layers': 11, 'dropout_rate': 0.22483366081717898, 'num_epochs': 18, 'learning_rate': 0.0006357424147269107}. Best is trial 13 with value: 4.033079147338867.\n",
      "[I 2025-04-07 18:33:47,020] Trial 25 finished with value: 4.050002098083496 and parameters: {'hidden_size': 92, 'num_layers': 14, 'dropout_rate': 0.17722604353222043, 'num_epochs': 22, 'learning_rate': 0.0008964817259390159}. Best is trial 13 with value: 4.033079147338867.\n",
      "[I 2025-04-07 18:33:50,313] Trial 26 finished with value: 3.934939384460449 and parameters: {'hidden_size': 68, 'num_layers': 10, 'dropout_rate': 0.12466996154936542, 'num_epochs': 18, 'learning_rate': 0.0007759320081816674}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:33:52,751] Trial 27 finished with value: 4.051291465759277 and parameters: {'hidden_size': 68, 'num_layers': 10, 'dropout_rate': 0.2727160847129129, 'num_epochs': 13, 'learning_rate': 0.0007967022640752485}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:33:56,707] Trial 28 finished with value: 4.042686939239502 and parameters: {'hidden_size': 84, 'num_layers': 10, 'dropout_rate': 0.16949214503398163, 'num_epochs': 18, 'learning_rate': 0.0007394069027200226}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:00,120] Trial 29 finished with value: 4.055243492126465 and parameters: {'hidden_size': 84, 'num_layers': 9, 'dropout_rate': 0.2471293384806531, 'num_epochs': 18, 'learning_rate': 0.0007308474163579189}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:02,648] Trial 30 finished with value: 4.058799743652344 and parameters: {'hidden_size': 72, 'num_layers': 10, 'dropout_rate': 0.17690287709704647, 'num_epochs': 13, 'learning_rate': 0.0005341321924950726}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:07,083] Trial 31 finished with value: 4.006143093109131 and parameters: {'hidden_size': 88, 'num_layers': 11, 'dropout_rate': 0.12941829942200636, 'num_epochs': 18, 'learning_rate': 0.0007734266310893398}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:10,074] Trial 32 finished with value: 4.043168544769287 and parameters: {'hidden_size': 80, 'num_layers': 8, 'dropout_rate': 0.16469570545621703, 'num_epochs': 18, 'learning_rate': 0.0006192395672870019}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:14,496] Trial 33 finished with value: 4.059012413024902 and parameters: {'hidden_size': 88, 'num_layers': 10, 'dropout_rate': 0.21366046961132262, 'num_epochs': 20, 'learning_rate': 0.0007627104348536238}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:17,489] Trial 34 finished with value: 4.078282356262207 and parameters: {'hidden_size': 88, 'num_layers': 8, 'dropout_rate': 0.1265379725867671, 'num_epochs': 16, 'learning_rate': 0.0006802496907636474}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:20,522] Trial 35 finished with value: 4.048830509185791 and parameters: {'hidden_size': 80, 'num_layers': 11, 'dropout_rate': 0.2641791869658461, 'num_epochs': 14, 'learning_rate': 0.0005727463281220152}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:23,129] Trial 36 finished with value: 4.053649425506592 and parameters: {'hidden_size': 64, 'num_layers': 9, 'dropout_rate': 0.19392561822191098, 'num_epochs': 17, 'learning_rate': 0.00045587690836415063}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:27,650] Trial 37 finished with value: 4.048355579376221 and parameters: {'hidden_size': 100, 'num_layers': 10, 'dropout_rate': 0.15696251542165135, 'num_epochs': 20, 'learning_rate': 0.0008411966455520914}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:32,253] Trial 38 finished with value: 4.058549880981445 and parameters: {'hidden_size': 84, 'num_layers': 11, 'dropout_rate': 0.35119820854614736, 'num_epochs': 19, 'learning_rate': 0.0006836120802073978}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:34,310] Trial 39 finished with value: 4.051051616668701 and parameters: {'hidden_size': 72, 'num_layers': 7, 'dropout_rate': 0.12187783154723049, 'num_epochs': 15, 'learning_rate': 0.0007752434768549857}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:37,635] Trial 40 finished with value: 4.046703338623047 and parameters: {'hidden_size': 88, 'num_layers': 9, 'dropout_rate': 0.2179601651339663, 'num_epochs': 17, 'learning_rate': 0.0007067470041803145}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:40,567] Trial 41 finished with value: 4.041518211364746 and parameters: {'hidden_size': 80, 'num_layers': 8, 'dropout_rate': 0.16723671170937487, 'num_epochs': 18, 'learning_rate': 0.0005943864655306346}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:43,363] Trial 42 finished with value: 4.058199882507324 and parameters: {'hidden_size': 84, 'num_layers': 7, 'dropout_rate': 0.1949720772743061, 'num_epochs': 19, 'learning_rate': 0.00047013230076814173}. Best is trial 26 with value: 3.934939384460449.\n",
      "[I 2025-04-07 18:34:45,921] Trial 43 finished with value: 3.8729567527770996 and parameters: {'hidden_size': 76, 'num_layers': 6, 'dropout_rate': 0.10127858530822872, 'num_epochs': 21, 'learning_rate': 0.0006403641213350133}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:34:47,996] Trial 44 finished with value: 4.05190372467041 and parameters: {'hidden_size': 68, 'num_layers': 5, 'dropout_rate': 0.11546870143686135, 'num_epochs': 21, 'learning_rate': 0.0006306978631007145}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:34:50,721] Trial 45 finished with value: 3.914809465408325 and parameters: {'hidden_size': 76, 'num_layers': 6, 'dropout_rate': 0.10271427913655316, 'num_epochs': 22, 'learning_rate': 0.00039064881367936694}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:34:53,338] Trial 46 finished with value: 4.063204288482666 and parameters: {'hidden_size': 72, 'num_layers': 6, 'dropout_rate': 0.10674188032022419, 'num_epochs': 22, 'learning_rate': 0.0003868732989018818}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:34:56,139] Trial 47 finished with value: 3.986426830291748 and parameters: {'hidden_size': 76, 'num_layers': 6, 'dropout_rate': 0.1325799747240168, 'num_epochs': 23, 'learning_rate': 0.0003138224959101924}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:34:58,210] Trial 48 finished with value: 4.025928974151611 and parameters: {'hidden_size': 76, 'num_layers': 5, 'dropout_rate': 0.10063300593484804, 'num_epochs': 20, 'learning_rate': 0.00025903747890934593}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:00,528] Trial 49 finished with value: 4.164520740509033 and parameters: {'hidden_size': 56, 'num_layers': 6, 'dropout_rate': 0.1329039481131324, 'num_epochs': 23, 'learning_rate': 0.0001807635579608151}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:04,197] Trial 50 finished with value: 5.128094673156738 and parameters: {'hidden_size': 76, 'num_layers': 7, 'dropout_rate': 0.4131283262236629, 'num_epochs': 25, 'learning_rate': 0.00036861764228784814}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:06,415] Trial 51 finished with value: 4.0593037605285645 and parameters: {'hidden_size': 76, 'num_layers': 5, 'dropout_rate': 0.10014208598113988, 'num_epochs': 21, 'learning_rate': 0.000263055104499168}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:08,317] Trial 52 finished with value: 4.077121257781982 and parameters: {'hidden_size': 68, 'num_layers': 5, 'dropout_rate': 0.12067907247939301, 'num_epochs': 20, 'learning_rate': 0.00029961151653087106}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:10,786] Trial 53 finished with value: 4.094452857971191 and parameters: {'hidden_size': 76, 'num_layers': 6, 'dropout_rate': 0.10090733861849291, 'num_epochs': 20, 'learning_rate': 0.00018060310854040935}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:13,052] Trial 54 finished with value: 4.053177833557129 and parameters: {'hidden_size': 64, 'num_layers': 6, 'dropout_rate': 0.14646168002446994, 'num_epochs': 22, 'learning_rate': 0.00041271172101877725}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:16,093] Trial 55 finished with value: 4.430410861968994 and parameters: {'hidden_size': 76, 'num_layers': 6, 'dropout_rate': 0.11732333162359047, 'num_epochs': 24, 'learning_rate': 7.661779220432695e-05}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:18,226] Trial 56 finished with value: 4.058665752410889 and parameters: {'hidden_size': 80, 'num_layers': 5, 'dropout_rate': 0.1448784965362041, 'num_epochs': 21, 'learning_rate': 0.00032492316259181406}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:21,363] Trial 57 finished with value: 4.093780517578125 and parameters: {'hidden_size': 72, 'num_layers': 7, 'dropout_rate': 0.13145704999774782, 'num_epochs': 23, 'learning_rate': 0.000250662845609802}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:23,383] Trial 58 finished with value: 4.015504360198975 and parameters: {'hidden_size': 76, 'num_layers': 5, 'dropout_rate': 0.11418272217343223, 'num_epochs': 19, 'learning_rate': 0.0005141438106482264}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:25,461] Trial 59 finished with value: 4.032228469848633 and parameters: {'hidden_size': 96, 'num_layers': 5, 'dropout_rate': 0.1519955602371847, 'num_epochs': 19, 'learning_rate': 0.0005286552291566311}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:27,692] Trial 60 finished with value: 4.072055816650391 and parameters: {'hidden_size': 68, 'num_layers': 7, 'dropout_rate': 0.18424666449326582, 'num_epochs': 17, 'learning_rate': 0.00042937743259230165}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:30,204] Trial 61 finished with value: 4.002430438995361 and parameters: {'hidden_size': 76, 'num_layers': 6, 'dropout_rate': 0.1149315232199202, 'num_epochs': 21, 'learning_rate': 0.00035491560139337176}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:32,812] Trial 62 finished with value: 4.039126396179199 and parameters: {'hidden_size': 80, 'num_layers': 6, 'dropout_rate': 0.1147713795597637, 'num_epochs': 21, 'learning_rate': 0.000496248315813883}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:35,127] Trial 63 finished with value: 4.414728164672852 and parameters: {'hidden_size': 72, 'num_layers': 6, 'dropout_rate': 0.13455466868007931, 'num_epochs': 19, 'learning_rate': 0.00034699103697242653}. Best is trial 43 with value: 3.8729567527770996.\n",
      "[I 2025-04-07 18:35:38,089] Trial 64 finished with value: 3.863400459289551 and parameters: {'hidden_size': 76, 'num_layers': 6, 'dropout_rate': 0.11452557126792819, 'num_epochs': 25, 'learning_rate': 0.0004002001447851646}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:35:42,022] Trial 65 finished with value: 4.026930332183838 and parameters: {'hidden_size': 80, 'num_layers': 8, 'dropout_rate': 0.1422463572976907, 'num_epochs': 25, 'learning_rate': 0.00039506542147334944}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:35:45,291] Trial 66 finished with value: 4.080351829528809 and parameters: {'hidden_size': 72, 'num_layers': 7, 'dropout_rate': 0.32762923909901204, 'num_epochs': 24, 'learning_rate': 0.00031113538964085293}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:35:49,162] Trial 67 finished with value: 4.979564189910889 and parameters: {'hidden_size': 76, 'num_layers': 7, 'dropout_rate': 0.47486122433070455, 'num_epochs': 27, 'learning_rate': 0.00036120377151101755}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:35:51,727] Trial 68 finished with value: 4.039888381958008 and parameters: {'hidden_size': 60, 'num_layers': 6, 'dropout_rate': 0.12438121033685617, 'num_epochs': 25, 'learning_rate': 0.0005699687193805284}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:35:54,927] Trial 69 finished with value: 4.049444675445557 and parameters: {'hidden_size': 68, 'num_layers': 8, 'dropout_rate': 0.1531404514015383, 'num_epochs': 22, 'learning_rate': 0.0006563630632243834}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:35:59,531] Trial 70 finished with value: 4.056850433349609 and parameters: {'hidden_size': 64, 'num_layers': 13, 'dropout_rate': 0.1291193321061348, 'num_epochs': 23, 'learning_rate': 0.0004808275544936613}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:01,206] Trial 71 finished with value: 4.038061141967773 and parameters: {'hidden_size': 76, 'num_layers': 5, 'dropout_rate': 0.11231410664861316, 'num_epochs': 16, 'learning_rate': 0.0004242113556055421}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:03,882] Trial 72 finished with value: 3.9679980278015137 and parameters: {'hidden_size': 72, 'num_layers': 6, 'dropout_rate': 0.10871072474082674, 'num_epochs': 22, 'learning_rate': 0.000526342638414703}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:06,630] Trial 73 finished with value: 3.9336259365081787 and parameters: {'hidden_size': 72, 'num_layers': 6, 'dropout_rate': 0.1411798068674842, 'num_epochs': 23, 'learning_rate': 0.000830436400149891}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:09,258] Trial 74 finished with value: 4.031739711761475 and parameters: {'hidden_size': 72, 'num_layers': 6, 'dropout_rate': 0.14081805556971505, 'num_epochs': 22, 'learning_rate': 0.0008383834873527444}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:12,522] Trial 75 finished with value: 4.05442476272583 and parameters: {'hidden_size': 72, 'num_layers': 7, 'dropout_rate': 0.15786919398734392, 'num_epochs': 24, 'learning_rate': 0.000551437186341926}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:15,558] Trial 76 finished with value: 4.0220465660095215 and parameters: {'hidden_size': 68, 'num_layers': 6, 'dropout_rate': 0.10686598517205806, 'num_epochs': 26, 'learning_rate': 0.00028202439584250555}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:18,310] Trial 77 finished with value: 4.0551042556762695 and parameters: {'hidden_size': 72, 'num_layers': 6, 'dropout_rate': 0.1206744061992352, 'num_epochs': 23, 'learning_rate': 0.000951558374756264}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:22,132] Trial 78 finished with value: 4.050787448883057 and parameters: {'hidden_size': 80, 'num_layers': 7, 'dropout_rate': 0.1814390770570668, 'num_epochs': 27, 'learning_rate': 0.0003983511852521953}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:24,722] Trial 79 finished with value: 3.957838535308838 and parameters: {'hidden_size': 76, 'num_layers': 6, 'dropout_rate': 0.16402891788144633, 'num_epochs': 22, 'learning_rate': 0.0007201898678787296}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:27,005] Trial 80 finished with value: 4.062425136566162 and parameters: {'hidden_size': 68, 'num_layers': 5, 'dropout_rate': 0.1655606808156897, 'num_epochs': 24, 'learning_rate': 0.0007204498521055724}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:29,481] Trial 81 finished with value: 3.880668878555298 and parameters: {'hidden_size': 76, 'num_layers': 6, 'dropout_rate': 0.10887372257840347, 'num_epochs': 21, 'learning_rate': 0.0006620615437119309}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:32,225] Trial 82 finished with value: 4.123814582824707 and parameters: {'hidden_size': 72, 'num_layers': 6, 'dropout_rate': 0.13892975621250114, 'num_epochs': 23, 'learning_rate': 0.0006602673475394221}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:35,287] Trial 83 finished with value: 4.007455825805664 and parameters: {'hidden_size': 76, 'num_layers': 7, 'dropout_rate': 0.1262840617305233, 'num_epochs': 22, 'learning_rate': 0.0007501146410623374}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:37,831] Trial 84 finished with value: 3.9268062114715576 and parameters: {'hidden_size': 80, 'num_layers': 6, 'dropout_rate': 0.1083775401525909, 'num_epochs': 21, 'learning_rate': 0.0007922725472374299}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:39,962] Trial 85 finished with value: 4.011090278625488 and parameters: {'hidden_size': 80, 'num_layers': 5, 'dropout_rate': 0.10942400421669865, 'num_epochs': 21, 'learning_rate': 0.0008265349341615017}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:42,696] Trial 86 finished with value: 3.892596483230591 and parameters: {'hidden_size': 80, 'num_layers': 6, 'dropout_rate': 0.1045763736529624, 'num_epochs': 22, 'learning_rate': 0.0008672701671068635}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:45,725] Trial 87 finished with value: 4.0103278160095215 and parameters: {'hidden_size': 84, 'num_layers': 7, 'dropout_rate': 0.10276733612132881, 'num_epochs': 21, 'learning_rate': 0.0007857327086005729}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:47,779] Trial 88 finished with value: 4.036401271820068 and parameters: {'hidden_size': 80, 'num_layers': 5, 'dropout_rate': 0.14817879152395716, 'num_epochs': 20, 'learning_rate': 0.0008603919819360662}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:50,942] Trial 89 finished with value: 3.8678088188171387 and parameters: {'hidden_size': 84, 'num_layers': 6, 'dropout_rate': 0.1247655761730234, 'num_epochs': 25, 'learning_rate': 0.0009028616877796307}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:36:58,718] Trial 90 finished with value: 4.036086559295654 and parameters: {'hidden_size': 84, 'num_layers': 15, 'dropout_rate': 0.12506501414279383, 'num_epochs': 26, 'learning_rate': 0.000895985497201958}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:37:01,372] Trial 91 finished with value: 3.8674302101135254 and parameters: {'hidden_size': 80, 'num_layers': 6, 'dropout_rate': 0.10046470157637151, 'num_epochs': 22, 'learning_rate': 0.0008027630356424267}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:37:04,434] Trial 92 finished with value: 3.901554822921753 and parameters: {'hidden_size': 84, 'num_layers': 6, 'dropout_rate': 0.11931118760146019, 'num_epochs': 24, 'learning_rate': 0.0008083340653825755}. Best is trial 64 with value: 3.863400459289551.\n",
      "[I 2025-04-07 18:37:07,595] Trial 93 finished with value: 3.8447790145874023 and parameters: {'hidden_size': 84, 'num_layers': 6, 'dropout_rate': 0.10973249327478134, 'num_epochs': 25, 'learning_rate': 0.0008048245472128958}. Best is trial 93 with value: 3.8447790145874023.\n",
      "[I 2025-04-07 18:37:10,800] Trial 94 finished with value: 3.847818374633789 and parameters: {'hidden_size': 84, 'num_layers': 6, 'dropout_rate': 0.10816904413621033, 'num_epochs': 25, 'learning_rate': 0.0008660203516805664}. Best is trial 93 with value: 3.8447790145874023.\n",
      "[I 2025-04-07 18:37:14,497] Trial 95 finished with value: 3.8676745891571045 and parameters: {'hidden_size': 84, 'num_layers': 7, 'dropout_rate': 0.10020268613141005, 'num_epochs': 25, 'learning_rate': 0.0008809762020199363}. Best is trial 93 with value: 3.8447790145874023.\n",
      "[I 2025-04-07 18:37:18,411] Trial 96 finished with value: 3.8122572898864746 and parameters: {'hidden_size': 88, 'num_layers': 7, 'dropout_rate': 0.10075118607271424, 'num_epochs': 25, 'learning_rate': 0.00094254830004061}. Best is trial 96 with value: 3.8122572898864746.\n",
      "[I 2025-04-07 18:37:22,710] Trial 97 finished with value: 3.84281063079834 and parameters: {'hidden_size': 88, 'num_layers': 7, 'dropout_rate': 0.10040067458328394, 'num_epochs': 28, 'learning_rate': 0.0009454885045801836}. Best is trial 96 with value: 3.8122572898864746.\n",
      "[I 2025-04-07 18:37:27,761] Trial 98 finished with value: 3.8056087493896484 and parameters: {'hidden_size': 88, 'num_layers': 8, 'dropout_rate': 0.1152572863386475, 'num_epochs': 29, 'learning_rate': 0.0009371413766206002}. Best is trial 98 with value: 3.8056087493896484.\n",
      "[I 2025-04-07 18:37:32,828] Trial 99 finished with value: 4.053371429443359 and parameters: {'hidden_size': 88, 'num_layers': 8, 'dropout_rate': 0.3849218310675592, 'num_epochs': 29, 'learning_rate': 0.0009690088202931831}. Best is trial 98 with value: 3.8056087493896484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value (Validation Loss): 3.8056087493896484\n",
      "  Params: \n",
      "    hidden_size: 88\n",
      "    num_layers: 8\n",
      "    dropout_rate: 0.1152572863386475\n",
      "    num_epochs: 29\n",
      "    learning_rate: 0.0009371413766206002\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value (Validation Loss): {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 88, 'num_layers': 8, 'dropout_rate': 0.1152572863386475, 'num_epochs': 29, 'learning_rate': 0.0009371413766206002}\n"
     ]
    }
   ],
   "source": [
    "print(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hidden_size = trial.params['hidden_size']\n",
    "best_num_layers = trial.params['num_layers']\n",
    "best_dropout_rate = trial.params['dropout_rate']\n",
    "best_num_epochs = trial.params['num_epochs']\n",
    "best_learning_rate = trial.params['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after Epoch: 2\n",
      "Model saved after Epoch: 3\n",
      "Model saved after Epoch: 7\n",
      "Model saved after Epoch: 8\n",
      "Model saved after Epoch: 10\n",
      "Model saved after Epoch: 11\n",
      "Model saved after Epoch: 16\n",
      "Model saved after Epoch: 17\n"
     ]
    }
   ],
   "source": [
    "# Merge the training and validation dataset 1 to train the final model\n",
    "final_train_dataset = voiceDataset(features[:train_size + val_size],\n",
    "                                    emotionLabels[:train_size + val_size], \n",
    "                                    strengthLabels[:train_size + val_size])\n",
    "\n",
    "final_trainDataLoader = DataLoader(final_train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "result = train_validate_model(hidden_size = best_hidden_size,\n",
    "                                  num_layers = best_num_layers,\n",
    "                                  dropout_rate = best_dropout_rate,\n",
    "                                  trainDataLoader = final_trainDataLoader,\n",
    "                                  #Use validationDataLoader_2 for the early stopping of the final model\n",
    "                                  validationDataLoader = validationDataLoader_2,\n",
    "                                  num_epochs = best_num_epochs,\n",
    "                                  learning_rate = best_learning_rate,\n",
    "                                  save = True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Accuracy: 0.5900\n",
      "Strength Accuracy: 0.8183\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "bestModel = FAN_Classifier(\n",
    "                       hidden_size = best_hidden_size,\n",
    "                       num_layers = best_num_layers,\n",
    "                       dropout_rate = best_dropout_rate,\n",
    "                       )\n",
    "\n",
    "bestModel.load_state_dict(torch.load('bestFAN.pth',map_location=device))\n",
    "\n",
    "bestModel.eval() #Set the bestModel to evaluation mode\n",
    "bestModel.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "  total = 0 #Total output for accuracy calculation\n",
    "  emoCorrect = 0 #Amount of correct prediction for accuracy calculation\n",
    "  strengthCorrect = 0\n",
    "  for batch in testDataLoader:\n",
    "      feature = batch['features'].to(device)\n",
    "      emoLabel = batch['emotionLabel'].to(device)\n",
    "      strengthLabel = batch['strengthLabel'].to(device)\n",
    "      \n",
    "      emoOutput, strengthOutput = bestModel(feature)\n",
    "      \n",
    "      emoPredicted = torch.argmax(emoOutput, dim = 1)\n",
    "      emoTarget = torch.argmax(emoLabel, dim=1)\n",
    "      \n",
    "      strengthPredicted = torch.argmax(strengthOutput, dim=1)\n",
    "      strengthTarget = torch.argmax(strengthLabel, dim=1)\n",
    "      \n",
    "            \n",
    "      total += emoLabel.size(0)\n",
    "      emoCorrect += (emoPredicted == emoTarget).sum().item()\n",
    "      strengthCorrect += (strengthPredicted == strengthTarget).sum().item()\n",
    "      \n",
    "  print(f\"Emotion Accuracy: {emoCorrect/total:.4f}\")\n",
    "  print(f\"Strength Accuracy: {strengthCorrect/total:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
