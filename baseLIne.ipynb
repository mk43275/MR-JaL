{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/asyncio/base_events.py\", line 595, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/asyncio/base_events.py\", line 1881, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/3y/2jj6w99n11g766vg19kpr73h0000gn/T/ipykernel_3821/4281350836.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403226260/work/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "#Mojo of reproducibility\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed):\n",
    "  #PyTorch\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  #Numpy\n",
    "  np.random.seed(seed)\n",
    "  #Python_random\n",
    "  random.seed(seed)\n",
    "  #CuDNN (when using CUDA)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class baseLineClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, dropout_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define a list of layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Define the first layer\n",
    "        self.layers.append(nn.Linear(173, hidden_size))\n",
    "        \n",
    "        # Define the intermediate hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        # Final layer to output\n",
    "        self.emo_output_layer = nn.Linear(hidden_size, 6)\n",
    "        self.strength_output_layer = nn.Linear(hidden_size, 3)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Pass through hidden layers\n",
    "        for layer in self.layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        # Output layers\n",
    "        emo_output = self.emo_output_layer(x)\n",
    "        strength_output = self.strength_output_layer(x)\n",
    "        \n",
    "        return emo_output, strength_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class voiceDataset(Dataset):\n",
    "    def __init__(self, features, emotionLabels, strengthLabels):\n",
    "        self.features = features\n",
    "        self.emotionLabels = emotionLabels\n",
    "        self.strengthLabels = strengthLabels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'features':self.features[idx], \n",
    "                'emotionLabel':self.emotionLabels[idx], \n",
    "                'strengthLabel':self.strengthLabels[idx]\n",
    "        }   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('featuresAndLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut corresponding columns of df into features and labels\n",
    "# Turn them into tensors\n",
    "features = df.iloc[:, 1:174].values\n",
    "features = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "emotionLabels = df.iloc[:,174:180].values\n",
    "emotionLabels = torch.tensor(emotionLabels, dtype=torch.float32)\n",
    "\n",
    "strengthLabels = df.iloc[:,180:183].values\n",
    "strengthLabels = torch.tensor(strengthLabels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5953 372 1117\n",
      "5953 372 372 1117\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "# train, validate, test = 8:1:1\n",
    "train_size = int(0.8 * len(df))\n",
    "val_size = int(0.05 * len(df))\n",
    "test_size = len(df) - train_size - val_size\n",
    "\n",
    "print(train_size, val_size, test_size)\n",
    "\n",
    "train_dataset = voiceDataset(features[:train_size], \n",
    "                             emotionLabels[:train_size], \n",
    "                             strengthLabels[:train_size])\n",
    "\n",
    "validate_dataset_1 = voiceDataset(features[train_size:train_size + val_size],\n",
    "                                emotionLabels[train_size:train_size + val_size], \n",
    "                                strengthLabels[train_size:train_size + val_size])\n",
    "\n",
    "validate_dataset_2 = voiceDataset(features[train_size + val_size:train_size + 2 * val_size],\n",
    "                                emotionLabels[train_size + val_size:train_size + 2 * val_size], \n",
    "                                strengthLabels[train_size + val_size:train_size + 2 * val_size])\n",
    "\n",
    "test_dataset = voiceDataset(features[train_size + val_size:],\n",
    "                            emotionLabels[train_size + val_size:], \n",
    "                            strengthLabels[train_size + val_size:])\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(len(train_dataset),len(validate_dataset_1), len(validate_dataset_2), len(test_dataset))\n",
    "\n",
    "# Create dataLoader\n",
    "trainDataLoader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "validationDataLoader_1 = DataLoader(validate_dataset_1,batch_size=128)\n",
    "validationDataLoader_2 = DataLoader(validate_dataset_2,batch_size=128)\n",
    "testDataLoader = DataLoader(test_dataset,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Define the trainer & validator function\n",
    "def train_validate_model(hidden_size = 0,\n",
    "                         num_layers = 0,\n",
    "                         dropout_rate = 0, \n",
    "                         trainDataLoader = None, \n",
    "                         validationDataLoader = None,\n",
    "                         num_epochs = 0, \n",
    "                         learning_rate = 0,\n",
    "                        save = False):\n",
    "\n",
    "    set_seed(42)\n",
    "\n",
    "    #Get the GPU as a device if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    #Instantiate the model\n",
    "    model = baseLineClassifier(hidden_size = hidden_size,\n",
    "                           num_layers = num_layers,\n",
    "                           dropout_rate = dropout_rate)\n",
    "\n",
    "    # Moving the model to GPU if available\n",
    "    model.to(device)\n",
    "\n",
    "    #Prepare the optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #Prepare the error function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    #Prepare the scheduler\n",
    "    #Reduce the learning rate by 0.1 if the validation loss does not decrease for 3 epochs\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    #Prepare the DataLoader\n",
    "    train_data_loader = trainDataLoader\n",
    "    validation_data_loader = validationDataLoader\n",
    "\n",
    "    #Placeholder for minimum validation loss\n",
    "    min_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        #set the model to training mode\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0 #Placeholder for training loss per epoch\n",
    "        for batch in train_data_loader:\n",
    "            feature = batch['features'].to(device)\n",
    "            emotionLabel = batch['emotionLabel'].to(device)\n",
    "            strengthLabel = batch['strengthLabel'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            emotionOutput, strengthOutput = model(feature)\n",
    "            #Calculate the loss for emotion head\n",
    "            emo_loss = criterion(emotionOutput, emotionLabel)\n",
    "            #Calculate the loss for strength head\n",
    "            strength_loss = criterion(strengthOutput, strengthLabel)\n",
    "            #Combine two losses to make a total loss. \n",
    "            #Put more weight on the emotion loss (7:3). Detecting emotion is more critical\n",
    "            loss = 0.7*emo_loss + 0.3*strength_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        #Validate the model\n",
    "        model.eval() #Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            total_samples = 0 #Total output for accuracy calculation\n",
    "            emoCorrect = 0 #Amount of correct prediction for accuracy calculation\n",
    "            strengthCorrect = 0\n",
    "            total_val_loss = 0 #Placeholder for validation loss per epoch\n",
    "            \n",
    "            for batch in validation_data_loader:\n",
    "                feature = batch['features'].to(device)\n",
    "                emotionLabel = batch['emotionLabel'].to(device)\n",
    "                strengthLabel = batch['strengthLabel'].to(device)\n",
    "                #Forward pass\n",
    "                emotionOutput, strengthOutput = model(feature)\n",
    "                emo_loss = criterion(emotionOutput, emotionLabel)\n",
    "                strength_loss = criterion(strengthOutput, strengthLabel )\n",
    "                total_val_loss += 0.7*emo_loss + 0.3*strength_loss\n",
    "                \n",
    "                # Get predicted emotion class & target emotion class\n",
    "                emo_predicted = torch.argmax(emotionOutput, dim=1)\n",
    "                emo_target = torch.argmax(emotionLabel, dim=1)\n",
    "                \n",
    "                # Get predicted strength class & target emotion class\n",
    "                strength_predicted = torch.argmax(strengthOutput,dim=1)\n",
    "                strength_target = torch.argmax(strengthLabel, dim=1 )\n",
    "                \n",
    "                emoCorrect += (emo_predicted == emo_target).sum().item()\n",
    "                strengthCorrect += (strength_predicted ==strength_target).sum().item()\n",
    "                \n",
    "                #Get total number of samples per epoch\n",
    "                total_samples += emotionLabel.size(0)\n",
    "\n",
    "            emo_accuracy = emoCorrect / total_samples\n",
    "            strength_accuracy = strengthCorrect / total_samples\n",
    "\n",
    "\n",
    "            #Print out the validation loss and accuracy per epoch\n",
    "            # print(f\"Epoch {epoch+1}/{num_epochs} | Training Loss: {total_loss:.4f}, Validation Loss: {total_val_loss:.4f}, Accuracy (Emotion): {emo_accuracy:.4f}, Accuracy (Strength): {strength_accuracy}\")\n",
    "\n",
    "            #pass the validation loss to the scheduler\n",
    "            scheduler.step(total_val_loss)\n",
    "\n",
    "        #If fineTuning = False, save the model with the lowest validation loss\n",
    "        #Save the first epoch model just in case\n",
    "\n",
    "            if epoch == 0:\n",
    "                min_val_loss = total_val_loss #Instantiate the min_val_loss at the first epoch\n",
    "                if save == True:\n",
    "                    torch.save(model.state_dict(), 'bestBaseLine.pth')\n",
    "            #Save the model if the validation loss is the lowest\n",
    "            elif total_val_loss < min_val_loss:\n",
    "                min_val_loss = total_val_loss\n",
    "                if save == True:\n",
    "                    torch.save(model.state_dict(), 'bestBaseLine.pth')\n",
    "                    print(f\"Model saved after Epoch: {epoch+1}\")\n",
    "                        \n",
    "\n",
    "    #Return the minimum validation loss for hyperparameter tuning\n",
    "    return min_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    set_seed(42)\n",
    "\n",
    "    #Define the hyperparameters to be tuned\n",
    "    #Dimension of the hidden layer \n",
    "    hidden_size = trial.suggest_int('hidden_size', 50, 100)\n",
    "    #Number of layers\n",
    "    num_layers = trial.suggest_int('num_layers', 5, 15)\n",
    "    #Dropout rate for the final feedforward network [0.1, 0.5]\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    #Number of epochs [10, 30]\n",
    "    num_epochs = trial.suggest_int('num_epochs', 10, 30)\n",
    "    #Learning rate for the optimizer [1e-5, 1e-3]\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3)\n",
    "\n",
    "    result = train_validate_model(hidden_size = hidden_size,\n",
    "                                  num_layers = num_layers,\n",
    "                                  dropout_rate = dropout_rate,\n",
    "                                  trainDataLoader = trainDataLoader,\n",
    "                                  validationDataLoader = validationDataLoader_1,\n",
    "                                  num_epochs = num_epochs,\n",
    "                                  learning_rate = learning_rate,\n",
    "                                  save = False\n",
    "                                  )\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 18:07:41,991] A new study created in memory with name: no-name-d23af7f3-9e94-4c61-9e92-ce9476092fae\n",
      "/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "[I 2025-04-07 18:07:44,545] Trial 0 finished with value: 4.341182708740234 and parameters: {'hidden_size': 71, 'num_layers': 5, 'dropout_rate': 0.3211330126779903, 'num_epochs': 26, 'learning_rate': 0.000623025984308101}. Best is trial 0 with value: 4.341182708740234.\n",
      "[I 2025-04-07 18:07:46,514] Trial 1 finished with value: 3.791170597076416 and parameters: {'hidden_size': 90, 'num_layers': 12, 'dropout_rate': 0.10814978374582496, 'num_epochs': 14, 'learning_rate': 0.0005839911828579195}. Best is trial 1 with value: 3.791170597076416.\n",
      "[I 2025-04-07 18:07:50,214] Trial 2 finished with value: 3.7564773559570312 and parameters: {'hidden_size': 65, 'num_layers': 13, 'dropout_rate': 0.10866204649800904, 'num_epochs': 29, 'learning_rate': 0.00068191430699639}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:07:52,746] Trial 3 finished with value: 4.056593894958496 and parameters: {'hidden_size': 74, 'num_layers': 10, 'dropout_rate': 0.24413008684002518, 'num_epochs': 23, 'learning_rate': 0.0009145313395809413}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:07:53,821] Trial 4 finished with value: 7.876481056213379 and parameters: {'hidden_size': 79, 'num_layers': 6, 'dropout_rate': 0.48389729652483077, 'num_epochs': 13, 'learning_rate': 2.6434981363584256e-05}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:07:55,915] Trial 5 finished with value: 4.078404426574707 and parameters: {'hidden_size': 69, 'num_layers': 13, 'dropout_rate': 0.4625690938519329, 'num_epochs': 16, 'learning_rate': 0.0005835644733862392}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:07:59,327] Trial 6 finished with value: 3.8222198486328125 and parameters: {'hidden_size': 95, 'num_layers': 10, 'dropout_rate': 0.21505731056290478, 'num_epochs': 27, 'learning_rate': 0.0005775797096510543}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:02,432] Trial 7 finished with value: 4.483788013458252 and parameters: {'hidden_size': 88, 'num_layers': 12, 'dropout_rate': 0.30642525604576576, 'num_epochs': 22, 'learning_rate': 9.104358340464633e-05}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:04,747] Trial 8 finished with value: 4.173799991607666 and parameters: {'hidden_size': 87, 'num_layers': 14, 'dropout_rate': 0.10314876137357626, 'num_epochs': 15, 'learning_rate': 0.00010123895389731408}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:06,418] Trial 9 finished with value: 4.438786029815674 and parameters: {'hidden_size': 60, 'num_layers': 5, 'dropout_rate': 0.3455626751625137, 'num_epochs': 26, 'learning_rate': 0.0002016207676979015}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:10,153] Trial 10 finished with value: 4.055306434631348 and parameters: {'hidden_size': 51, 'num_layers': 15, 'dropout_rate': 0.17565920562086837, 'num_epochs': 30, 'learning_rate': 0.0008960247759247381}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:11,278] Trial 11 finished with value: 3.9562368392944336 and parameters: {'hidden_size': 62, 'num_layers': 12, 'dropout_rate': 0.10169277025092177, 'num_epochs': 10, 'learning_rate': 0.00040749285905155555}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:13,334] Trial 12 finished with value: 3.80792236328125 and parameters: {'hidden_size': 83, 'num_layers': 9, 'dropout_rate': 0.15390699177543804, 'num_epochs': 19, 'learning_rate': 0.0007401188921719754}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:15,269] Trial 13 finished with value: 4.28858757019043 and parameters: {'hidden_size': 99, 'num_layers': 8, 'dropout_rate': 0.38232586085653947, 'num_epochs': 18, 'learning_rate': 0.0003611926787933369}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:16,470] Trial 14 finished with value: 4.062734603881836 and parameters: {'hidden_size': 65, 'num_layers': 12, 'dropout_rate': 0.16283127658111674, 'num_epochs': 10, 'learning_rate': 0.0007736873581206708}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:19,188] Trial 15 finished with value: 4.056220531463623 and parameters: {'hidden_size': 54, 'num_layers': 15, 'dropout_rate': 0.2684047819213631, 'num_epochs': 22, 'learning_rate': 0.0004183742301960084}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:21,138] Trial 16 finished with value: 4.01529598236084 and parameters: {'hidden_size': 92, 'num_layers': 13, 'dropout_rate': 0.2038611692126261, 'num_epochs': 13, 'learning_rate': 0.0007420768925696725}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:24,687] Trial 17 finished with value: 3.807617664337158 and parameters: {'hidden_size': 76, 'num_layers': 11, 'dropout_rate': 0.1257291651424656, 'num_epochs': 30, 'learning_rate': 0.0002598473061441468}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:26,699] Trial 18 finished with value: 4.056522369384766 and parameters: {'hidden_size': 57, 'num_layers': 14, 'dropout_rate': 0.3866490138306164, 'num_epochs': 17, 'learning_rate': 0.0006597251038986247}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:28,659] Trial 19 finished with value: 4.0785017013549805 and parameters: {'hidden_size': 81, 'num_layers': 8, 'dropout_rate': 0.25348635087466437, 'num_epochs': 20, 'learning_rate': 0.0005251914681791936}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:30,688] Trial 20 finished with value: 3.8229055404663086 and parameters: {'hidden_size': 100, 'num_layers': 13, 'dropout_rate': 0.14422964266068034, 'num_epochs': 13, 'learning_rate': 0.0008629546681273933}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:33,915] Trial 21 finished with value: 3.837925434112549 and parameters: {'hidden_size': 67, 'num_layers': 11, 'dropout_rate': 0.1257724205479589, 'num_epochs': 29, 'learning_rate': 0.00031750169192564805}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:37,318] Trial 22 finished with value: 4.072846412658691 and parameters: {'hidden_size': 75, 'num_layers': 11, 'dropout_rate': 0.190828390184417, 'num_epochs': 28, 'learning_rate': 0.0002605310265467038}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:40,298] Trial 23 finished with value: 3.783231735229492 and parameters: {'hidden_size': 76, 'num_layers': 11, 'dropout_rate': 0.12926325547433526, 'num_epochs': 25, 'learning_rate': 0.00047610829593824195}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:42,873] Trial 24 finished with value: 3.7824878692626953 and parameters: {'hidden_size': 85, 'num_layers': 9, 'dropout_rate': 0.10393492818087716, 'num_epochs': 24, 'learning_rate': 0.0004877726572971926}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:45,271] Trial 25 finished with value: 3.9690747261047363 and parameters: {'hidden_size': 84, 'num_layers': 8, 'dropout_rate': 0.21956030628270473, 'num_epochs': 24, 'learning_rate': 0.0004835276563410298}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:47,658] Trial 26 finished with value: 3.844794988632202 and parameters: {'hidden_size': 72, 'num_layers': 9, 'dropout_rate': 0.1436282844932699, 'num_epochs': 24, 'learning_rate': 0.00047919194941414026}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:49,831] Trial 27 finished with value: 3.807750701904297 and parameters: {'hidden_size': 78, 'num_layers': 7, 'dropout_rate': 0.18200272734607428, 'num_epochs': 25, 'learning_rate': 0.0006709805008330127}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:52,309] Trial 28 finished with value: 3.7954115867614746 and parameters: {'hidden_size': 64, 'num_layers': 9, 'dropout_rate': 0.13659573509433687, 'num_epochs': 28, 'learning_rate': 0.00050151915022659}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:54,997] Trial 29 finished with value: 3.805778980255127 and parameters: {'hidden_size': 70, 'num_layers': 10, 'dropout_rate': 0.17296066833646392, 'num_epochs': 26, 'learning_rate': 0.0009853693246512606}. Best is trial 2 with value: 3.7564773559570312.\n",
      "[I 2025-04-07 18:08:58,212] Trial 30 finished with value: 3.7552030086517334 and parameters: {'hidden_size': 84, 'num_layers': 14, 'dropout_rate': 0.10143192812086363, 'num_epochs': 21, 'learning_rate': 0.0006859293824007591}. Best is trial 30 with value: 3.7552030086517334.\n",
      "[I 2025-04-07 18:09:01,524] Trial 31 finished with value: 3.7654805183410645 and parameters: {'hidden_size': 85, 'num_layers': 14, 'dropout_rate': 0.12050145870374838, 'num_epochs': 21, 'learning_rate': 0.00065933980310427}. Best is trial 30 with value: 3.7552030086517334.\n",
      "[I 2025-04-07 18:09:04,914] Trial 32 finished with value: 3.7689762115478516 and parameters: {'hidden_size': 85, 'num_layers': 14, 'dropout_rate': 0.10375685259243908, 'num_epochs': 21, 'learning_rate': 0.000814225715534915}. Best is trial 30 with value: 3.7552030086517334.\n",
      "[I 2025-04-07 18:09:08,351] Trial 33 finished with value: 3.753312110900879 and parameters: {'hidden_size': 92, 'num_layers': 14, 'dropout_rate': 0.1234050396860964, 'num_epochs': 21, 'learning_rate': 0.0008063990565325594}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:11,740] Trial 34 finished with value: 3.8580069541931152 and parameters: {'hidden_size': 93, 'num_layers': 15, 'dropout_rate': 0.15823309944338393, 'num_epochs': 20, 'learning_rate': 0.0006848996416636863}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:14,894] Trial 35 finished with value: 4.055737495422363 and parameters: {'hidden_size': 90, 'num_layers': 14, 'dropout_rate': 0.231999294424305, 'num_epochs': 19, 'learning_rate': 0.0006288066233279332}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:18,453] Trial 36 finished with value: 3.7588140964508057 and parameters: {'hidden_size': 95, 'num_layers': 13, 'dropout_rate': 0.12389202250065211, 'num_epochs': 22, 'learning_rate': 0.0007968028122385804}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:21,747] Trial 37 finished with value: 4.046664237976074 and parameters: {'hidden_size': 96, 'num_layers': 13, 'dropout_rate': 0.27523600100708967, 'num_epochs': 22, 'learning_rate': 0.0009702132068264514}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:24,436] Trial 38 finished with value: 4.054799556732178 and parameters: {'hidden_size': 97, 'num_layers': 13, 'dropout_rate': 0.44124012627781506, 'num_epochs': 18, 'learning_rate': 0.0008262292806259928}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:26,958] Trial 39 finished with value: 3.9172849655151367 and parameters: {'hidden_size': 89, 'num_layers': 15, 'dropout_rate': 0.1863965962558587, 'num_epochs': 16, 'learning_rate': 0.0007427622554602527}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:30,075] Trial 40 finished with value: 3.8154349327087402 and parameters: {'hidden_size': 92, 'num_layers': 12, 'dropout_rate': 0.20121693366088847, 'num_epochs': 23, 'learning_rate': 0.0009215366507050985}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:33,261] Trial 41 finished with value: 3.795689344406128 and parameters: {'hidden_size': 80, 'num_layers': 14, 'dropout_rate': 0.1264755077094759, 'num_epochs': 22, 'learning_rate': 0.0005891622030172439}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:36,322] Trial 42 finished with value: 3.7689380645751953 and parameters: {'hidden_size': 87, 'num_layers': 13, 'dropout_rate': 0.11826037576446397, 'num_epochs': 21, 'learning_rate': 0.0007045312949542756}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:39,675] Trial 43 finished with value: 3.7950923442840576 and parameters: {'hidden_size': 93, 'num_layers': 14, 'dropout_rate': 0.1579548518877486, 'num_epochs': 21, 'learning_rate': 0.000792900495224084}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:42,625] Trial 44 finished with value: 3.9055261611938477 and parameters: {'hidden_size': 82, 'num_layers': 15, 'dropout_rate': 0.11987203406632706, 'num_epochs': 19, 'learning_rate': 0.0005551002629421858}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:46,047] Trial 45 finished with value: 3.7916321754455566 and parameters: {'hidden_size': 87, 'num_layers': 12, 'dropout_rate': 0.15144998507464413, 'num_epochs': 23, 'learning_rate': 0.0008576628876251514}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:48,856] Trial 46 finished with value: 3.8081812858581543 and parameters: {'hidden_size': 90, 'num_layers': 14, 'dropout_rate': 0.138513621452172, 'num_epochs': 18, 'learning_rate': 0.0006281549267248858}. Best is trial 33 with value: 3.753312110900879.\n",
      "[I 2025-04-07 18:09:53,190] Trial 47 finished with value: 3.7298619747161865 and parameters: {'hidden_size': 96, 'num_layers': 13, 'dropout_rate': 0.10127091596686894, 'num_epochs': 27, 'learning_rate': 0.0007174150430910677}. Best is trial 47 with value: 3.7298619747161865.\n",
      "[I 2025-04-07 18:09:57,380] Trial 48 finished with value: 4.055411338806152 and parameters: {'hidden_size': 98, 'num_layers': 13, 'dropout_rate': 0.3249875115512768, 'num_epochs': 27, 'learning_rate': 0.0007191429376612362}. Best is trial 47 with value: 3.7298619747161865.\n",
      "[I 2025-04-07 18:10:01,314] Trial 49 finished with value: 3.7477219104766846 and parameters: {'hidden_size': 95, 'num_layers': 12, 'dropout_rate': 0.10033704704934622, 'num_epochs': 27, 'learning_rate': 0.000764935196790662}. Best is trial 47 with value: 3.7298619747161865.\n",
      "[I 2025-04-07 18:10:05,155] Trial 50 finished with value: 3.727235794067383 and parameters: {'hidden_size': 94, 'num_layers': 12, 'dropout_rate': 0.10799179549655347, 'num_epochs': 27, 'learning_rate': 0.000768151521099264}. Best is trial 50 with value: 3.727235794067383.\n",
      "[I 2025-04-07 18:10:09,011] Trial 51 finished with value: 3.7442684173583984 and parameters: {'hidden_size': 95, 'num_layers': 12, 'dropout_rate': 0.10728572053530427, 'num_epochs': 27, 'learning_rate': 0.0008596706607719168}. Best is trial 50 with value: 3.727235794067383.\n",
      "[I 2025-04-07 18:10:12,922] Trial 52 finished with value: 3.7456154823303223 and parameters: {'hidden_size': 95, 'num_layers': 12, 'dropout_rate': 0.10215400158798325, 'num_epochs': 27, 'learning_rate': 0.0009066329802712047}. Best is trial 50 with value: 3.727235794067383.\n",
      "[I 2025-04-07 18:10:16,833] Trial 53 finished with value: 3.7354958057403564 and parameters: {'hidden_size': 95, 'num_layers': 12, 'dropout_rate': 0.11215199579503247, 'num_epochs': 27, 'learning_rate': 0.0009063194959042567}. Best is trial 50 with value: 3.727235794067383.\n",
      "[I 2025-04-07 18:10:20,858] Trial 54 finished with value: 3.7319114208221436 and parameters: {'hidden_size': 95, 'num_layers': 12, 'dropout_rate': 0.10187329916444744, 'num_epochs': 27, 'learning_rate': 0.0008973148805315607}. Best is trial 50 with value: 3.727235794067383.\n",
      "[I 2025-04-07 18:10:24,895] Trial 55 finished with value: 3.7921619415283203 and parameters: {'hidden_size': 100, 'num_layers': 11, 'dropout_rate': 0.16987049498978807, 'num_epochs': 28, 'learning_rate': 0.000935387813153922}. Best is trial 50 with value: 3.727235794067383.\n",
      "[I 2025-04-07 18:10:28,647] Trial 56 finished with value: 3.7331202030181885 and parameters: {'hidden_size': 98, 'num_layers': 10, 'dropout_rate': 0.14499763233672222, 'num_epochs': 29, 'learning_rate': 0.0008834251891426269}. Best is trial 50 with value: 3.727235794067383.\n",
      "[I 2025-04-07 18:10:32,488] Trial 57 finished with value: 3.7606518268585205 and parameters: {'hidden_size': 98, 'num_layers': 10, 'dropout_rate': 0.1425280428033558, 'num_epochs': 29, 'learning_rate': 0.0008747445987505214}. Best is trial 50 with value: 3.727235794067383.\n",
      "[I 2025-04-07 18:10:36,568] Trial 58 finished with value: 3.723954200744629 and parameters: {'hidden_size': 97, 'num_layers': 11, 'dropout_rate': 0.11544984990942149, 'num_epochs': 30, 'learning_rate': 0.0009519637380933904}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:10:40,629] Trial 59 finished with value: 3.7645366191864014 and parameters: {'hidden_size': 100, 'num_layers': 11, 'dropout_rate': 0.16727390681748022, 'num_epochs': 30, 'learning_rate': 0.0009529313854573929}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:10:44,441] Trial 60 finished with value: 3.7517216205596924 and parameters: {'hidden_size': 97, 'num_layers': 10, 'dropout_rate': 0.13897804022079877, 'num_epochs': 29, 'learning_rate': 0.0009856215597931525}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:10:48,559] Trial 61 finished with value: 3.7481651306152344 and parameters: {'hidden_size': 93, 'num_layers': 11, 'dropout_rate': 0.1166194355008168, 'num_epochs': 28, 'learning_rate': 0.000843366893451843}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:10:52,807] Trial 62 finished with value: 3.737638473510742 and parameters: {'hidden_size': 94, 'num_layers': 12, 'dropout_rate': 0.1120336856181262, 'num_epochs': 26, 'learning_rate': 0.0008859421563350991}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:10:56,442] Trial 63 finished with value: 3.7613630294799805 and parameters: {'hidden_size': 98, 'num_layers': 11, 'dropout_rate': 0.1482409927470377, 'num_epochs': 26, 'learning_rate': 0.0008952909292381918}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:00,613] Trial 64 finished with value: 3.7375011444091797 and parameters: {'hidden_size': 91, 'num_layers': 12, 'dropout_rate': 0.11263871959436968, 'num_epochs': 30, 'learning_rate': 0.000919543559877941}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:04,228] Trial 65 finished with value: 3.744006395339966 and parameters: {'hidden_size': 91, 'num_layers': 10, 'dropout_rate': 0.1335210102280333, 'num_epochs': 30, 'learning_rate': 0.0009266581511167149}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:08,535] Trial 66 finished with value: 3.7509469985961914 and parameters: {'hidden_size': 97, 'num_layers': 12, 'dropout_rate': 0.11318817200112508, 'num_epochs': 30, 'learning_rate': 0.0009989867325115134}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:12,154] Trial 67 finished with value: 4.055817604064941 and parameters: {'hidden_size': 88, 'num_layers': 11, 'dropout_rate': 0.3661952315253044, 'num_epochs': 29, 'learning_rate': 0.0009423253546870062}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:15,731] Trial 68 finished with value: 3.7854835987091064 and parameters: {'hidden_size': 99, 'num_layers': 12, 'dropout_rate': 0.15317313569588395, 'num_epochs': 25, 'learning_rate': 0.000765064341414695}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:19,218] Trial 69 finished with value: 3.7721872329711914 and parameters: {'hidden_size': 96, 'num_layers': 10, 'dropout_rate': 0.13343735628766795, 'num_epochs': 29, 'learning_rate': 0.0008364993874400434}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:21,406] Trial 70 finished with value: 3.740285873413086 and parameters: {'hidden_size': 94, 'num_layers': 5, 'dropout_rate': 0.11361010939824313, 'num_epochs': 28, 'learning_rate': 0.0009588442873851036}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:25,157] Trial 71 finished with value: 3.726409435272217 and parameters: {'hidden_size': 94, 'num_layers': 12, 'dropout_rate': 0.11028015907871341, 'num_epochs': 26, 'learning_rate': 0.0008857632486333442}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:28,862] Trial 72 finished with value: 3.7521727085113525 and parameters: {'hidden_size': 91, 'num_layers': 11, 'dropout_rate': 0.13313257556312946, 'num_epochs': 28, 'learning_rate': 0.0009029762254218206}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:32,540] Trial 73 finished with value: 3.7459564208984375 and parameters: {'hidden_size': 99, 'num_layers': 12, 'dropout_rate': 0.11200822638200139, 'num_epochs': 25, 'learning_rate': 0.0008699320658648314}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:36,883] Trial 74 finished with value: 4.055920600891113 and parameters: {'hidden_size': 96, 'num_layers': 13, 'dropout_rate': 0.490114821109772, 'num_epochs': 29, 'learning_rate': 0.0009683906823399174}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:41,456] Trial 75 finished with value: 4.055250644683838 and parameters: {'hidden_size': 93, 'num_layers': 13, 'dropout_rate': 0.4282060749907911, 'num_epochs': 30, 'learning_rate': 0.0008306979567318065}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:45,060] Trial 76 finished with value: 3.7695376873016357 and parameters: {'hidden_size': 91, 'num_layers': 11, 'dropout_rate': 0.1277909042451776, 'num_epochs': 27, 'learning_rate': 0.0009157029248718641}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:48,984] Trial 77 finished with value: 3.7688465118408203 and parameters: {'hidden_size': 89, 'num_layers': 13, 'dropout_rate': 0.14761760498054116, 'num_epochs': 26, 'learning_rate': 0.0007813863845390957}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:53,018] Trial 78 finished with value: 3.7653157711029053 and parameters: {'hidden_size': 94, 'num_layers': 12, 'dropout_rate': 0.18096797447134438, 'num_epochs': 28, 'learning_rate': 0.0008787712418973181}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:11:57,193] Trial 79 finished with value: 3.783555269241333 and parameters: {'hidden_size': 97, 'num_layers': 12, 'dropout_rate': 0.16376774093902263, 'num_epochs': 29, 'learning_rate': 0.0009418323238226296}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:00,755] Trial 80 finished with value: 3.7376725673675537 and parameters: {'hidden_size': 100, 'num_layers': 11, 'dropout_rate': 0.10123852031635468, 'num_epochs': 26, 'learning_rate': 0.0008143951132546384}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:04,607] Trial 81 finished with value: 3.741865634918213 and parameters: {'hidden_size': 94, 'num_layers': 12, 'dropout_rate': 0.11638152667997212, 'num_epochs': 25, 'learning_rate': 0.0008892359507914435}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:06,370] Trial 82 finished with value: 4.383169174194336 and parameters: {'hidden_size': 92, 'num_layers': 12, 'dropout_rate': 0.11302077816311955, 'num_epochs': 11, 'learning_rate': 3.0662254563159e-05}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:10,349] Trial 83 finished with value: 3.7594943046569824 and parameters: {'hidden_size': 96, 'num_layers': 12, 'dropout_rate': 0.12613115677286077, 'num_epochs': 27, 'learning_rate': 0.0008487293053255238}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:15,608] Trial 84 finished with value: 3.732569694519043 and parameters: {'hidden_size': 94, 'num_layers': 13, 'dropout_rate': 0.11109396378461185, 'num_epochs': 30, 'learning_rate': 0.0008967035599195869}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:20,540] Trial 85 finished with value: 4.055037975311279 and parameters: {'hidden_size': 98, 'num_layers': 13, 'dropout_rate': 0.2838670296187147, 'num_epochs': 30, 'learning_rate': 0.0009190169735627537}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:23,263] Trial 86 finished with value: 3.7438762187957764 and parameters: {'hidden_size': 89, 'num_layers': 6, 'dropout_rate': 0.10024446779866947, 'num_epochs': 28, 'learning_rate': 0.0009779775832520763}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:28,168] Trial 87 finished with value: 3.7892260551452637 and parameters: {'hidden_size': 96, 'num_layers': 13, 'dropout_rate': 0.14076156996682254, 'num_epochs': 29, 'learning_rate': 0.0008139513940619887}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:31,747] Trial 88 finished with value: 3.751211643218994 and parameters: {'hidden_size': 92, 'num_layers': 9, 'dropout_rate': 0.12275432124906918, 'num_epochs': 30, 'learning_rate': 0.0007578193754205071}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:36,327] Trial 89 finished with value: 3.7538399696350098 and parameters: {'hidden_size': 99, 'num_layers': 11, 'dropout_rate': 0.11040718459129559, 'num_epochs': 27, 'learning_rate': 0.0007266865656828678}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:40,419] Trial 90 finished with value: 3.8038394451141357 and parameters: {'hidden_size': 60, 'num_layers': 13, 'dropout_rate': 0.13186862505096178, 'num_epochs': 28, 'learning_rate': 0.0004494150469224119}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:44,351] Trial 91 finished with value: 3.7334024906158447 and parameters: {'hidden_size': 94, 'num_layers': 12, 'dropout_rate': 0.11016040984067724, 'num_epochs': 26, 'learning_rate': 0.0008902393556497139}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:50,249] Trial 92 finished with value: 3.736438274383545 and parameters: {'hidden_size': 95, 'num_layers': 13, 'dropout_rate': 0.12135844255620629, 'num_epochs': 24, 'learning_rate': 0.0009395954902759396}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:54,992] Trial 93 finished with value: 3.740565061569214 and parameters: {'hidden_size': 95, 'num_layers': 13, 'dropout_rate': 0.1244260623697124, 'num_epochs': 24, 'learning_rate': 0.0009508174006515778}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:12:58,808] Trial 94 finished with value: 3.804568290710449 and parameters: {'hidden_size': 93, 'num_layers': 13, 'dropout_rate': 0.1559602965321888, 'num_epochs': 25, 'learning_rate': 0.0009957924454443525}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:13:02,630] Trial 95 finished with value: 3.731736660003662 and parameters: {'hidden_size': 97, 'num_layers': 12, 'dropout_rate': 0.10755915103444165, 'num_epochs': 26, 'learning_rate': 0.0008632863507161359}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:13:07,263] Trial 96 finished with value: 3.731297016143799 and parameters: {'hidden_size': 97, 'num_layers': 11, 'dropout_rate': 0.10696402174326615, 'num_epochs': 26, 'learning_rate': 0.000857142522192807}. Best is trial 58 with value: 3.723954200744629.\n",
      "[I 2025-04-07 18:13:10,694] Trial 97 finished with value: 3.71651291847229 and parameters: {'hidden_size': 98, 'num_layers': 10, 'dropout_rate': 0.10490512300502887, 'num_epochs': 26, 'learning_rate': 0.0007927957821197512}. Best is trial 97 with value: 3.71651291847229.\n",
      "[I 2025-04-07 18:13:14,343] Trial 98 finished with value: 3.7174596786499023 and parameters: {'hidden_size': 98, 'num_layers': 10, 'dropout_rate': 0.10073493975539292, 'num_epochs': 26, 'learning_rate': 0.0007860165131770238}. Best is trial 97 with value: 3.71651291847229.\n",
      "[I 2025-04-07 18:13:17,769] Trial 99 finished with value: 3.7269251346588135 and parameters: {'hidden_size': 97, 'num_layers': 10, 'dropout_rate': 0.10097433145502063, 'num_epochs': 25, 'learning_rate': 0.0007880165701855512}. Best is trial 97 with value: 3.71651291847229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value (Validation Loss): 3.71651291847229\n",
      "  Params: \n",
      "    hidden_size: 98\n",
      "    num_layers: 10\n",
      "    dropout_rate: 0.10490512300502887\n",
      "    num_epochs: 26\n",
      "    learning_rate: 0.0007927957821197512\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value (Validation Loss): {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 98, 'num_layers': 10, 'dropout_rate': 0.10490512300502887, 'num_epochs': 26, 'learning_rate': 0.0007927957821197512}\n"
     ]
    }
   ],
   "source": [
    "print(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hidden_size = trial.params['hidden_size']\n",
    "best_num_layers = trial.params['num_layers']\n",
    "best_dropout_rate = trial.params['dropout_rate']\n",
    "best_num_epochs = trial.params['num_epochs']\n",
    "best_learning_rate = trial.params['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after Epoch: 2\n",
      "Model saved after Epoch: 3\n",
      "Model saved after Epoch: 4\n",
      "Model saved after Epoch: 5\n",
      "Model saved after Epoch: 7\n",
      "Model saved after Epoch: 9\n",
      "Model saved after Epoch: 10\n",
      "Model saved after Epoch: 11\n",
      "Model saved after Epoch: 12\n",
      "Model saved after Epoch: 13\n",
      "Model saved after Epoch: 14\n",
      "Model saved after Epoch: 15\n",
      "Model saved after Epoch: 16\n",
      "Model saved after Epoch: 18\n",
      "Model saved after Epoch: 22\n",
      "Model saved after Epoch: 23\n",
      "Model saved after Epoch: 24\n"
     ]
    }
   ],
   "source": [
    "# Merge the training and validation dataset 1 to train the final model\n",
    "final_train_dataset = voiceDataset(features[:train_size + val_size],\n",
    "                                    emotionLabels[:train_size + val_size], \n",
    "                                    strengthLabels[:train_size + val_size])\n",
    "\n",
    "final_trainDataLoader = DataLoader(final_train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "result = train_validate_model(hidden_size = best_hidden_size,\n",
    "                                  num_layers = best_num_layers,\n",
    "                                  dropout_rate = best_dropout_rate,\n",
    "                                  trainDataLoader = final_trainDataLoader,\n",
    "                                  #Use validationDataLoader_2 for the early stopping of the final model\n",
    "                                  validationDataLoader = validationDataLoader_2,\n",
    "                                  num_epochs = best_num_epochs,\n",
    "                                  learning_rate = best_learning_rate,\n",
    "                                  save = True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Accuracy: 0.6535\n",
      "Strength Accuracy: 0.8183\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "bestModel = baseLineClassifier(\n",
    "                       hidden_size = best_hidden_size,\n",
    "                       num_layers = best_num_layers,\n",
    "                       dropout_rate = best_dropout_rate,\n",
    "                       )\n",
    "\n",
    "bestModel.load_state_dict(torch.load('bestBaseLine.pth',map_location=device))\n",
    "\n",
    "bestModel.eval() #Set the bestModel to evaluation mode\n",
    "bestModel.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "  total = 0 #Total output for accuracy calculation\n",
    "  emoCorrect = 0 #Amount of correct prediction for accuracy calculation\n",
    "  strengthCorrect = 0\n",
    "  for batch in testDataLoader:\n",
    "      feature = batch['features'].to(device)\n",
    "      emoLabel = batch['emotionLabel'].to(device)\n",
    "      strengthLabel = batch['strengthLabel'].to(device)\n",
    "      \n",
    "      emoOutput, strengthOutput = bestModel(feature)\n",
    "      \n",
    "      emoPredicted = torch.argmax(emoOutput, dim = 1)\n",
    "      emoTarget = torch.argmax(emoLabel, dim=1)\n",
    "      \n",
    "      strengthPredicted = torch.argmax(strengthOutput, dim=1)\n",
    "      strengthTarget = torch.argmax(strengthLabel, dim=1)\n",
    "      \n",
    "            \n",
    "      total += emoLabel.size(0)\n",
    "      emoCorrect += (emoPredicted == emoTarget).sum().item()\n",
    "      strengthCorrect += (strengthPredicted == strengthTarget).sum().item()\n",
    "      \n",
    "  print(f\"Emotion Accuracy: {emoCorrect/total:.4f}\")\n",
    "  print(f\"Strength Accuracy: {strengthCorrect/total:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
