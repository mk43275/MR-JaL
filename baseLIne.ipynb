{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/asyncio/base_events.py\", line 595, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/asyncio/base_events.py\", line 1881, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/3y/2jj6w99n11g766vg19kpr73h0000gn/T/ipykernel_55821/4281350836.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/takehararyoutarou/anaconda3/envs/mlVenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403226260/work/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "#Mojo of reproducibility\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed):\n",
    "  #PyTorch\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  #Numpy\n",
    "  np.random.seed(seed)\n",
    "  #Python_random\n",
    "  random.seed(seed)\n",
    "  #CuDNN (when using CUDA)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class baseLineClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, dropout_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define a list of layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Define the first layer\n",
    "        self.layers.append(nn.Linear(173, hidden_size))\n",
    "        \n",
    "        # Define the intermediate hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        # Final layer to output\n",
    "        self.emo_output_layer = nn.Linear(hidden_size, 6)\n",
    "        self.strength_output_layer = nn.Linear(hidden_size, 3)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Pass through hidden layers\n",
    "        for layer in self.layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        # Output layers\n",
    "        emo_output = self.emo_output_layer(x)\n",
    "        strength_output = self.strength_output_layer(x)\n",
    "        \n",
    "        return emo_output, strength_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class voiceDataset(Dataset):\n",
    "    def __init__(self, features, emotionLabels, strengthLabels):\n",
    "        self.features = features\n",
    "        self.emotionLabels = emotionLabels\n",
    "        self.strengthLabels = strengthLabels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'features':self.features[idx], \n",
    "                'emotionLabel':self.emotionLabels[idx], \n",
    "                'strengthLabel':self.strengthLabels[idx]\n",
    "        }   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('featuresAndLabels.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7442\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clipName</th>\n",
       "      <th>mfcc_0</th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>...</th>\n",
       "      <th>tonnets_172</th>\n",
       "      <th>N</th>\n",
       "      <th>A</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1022_ITS_ANG_XX</td>\n",
       "      <td>-625.058655</td>\n",
       "      <td>-4.994524</td>\n",
       "      <td>-5.040599</td>\n",
       "      <td>31.118151</td>\n",
       "      <td>-11.813456</td>\n",
       "      <td>-14.570557</td>\n",
       "      <td>0.724647</td>\n",
       "      <td>-9.413414</td>\n",
       "      <td>-3.972650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1037_ITS_ANG_XX</td>\n",
       "      <td>-648.157227</td>\n",
       "      <td>-10.045857</td>\n",
       "      <td>7.429339</td>\n",
       "      <td>20.802429</td>\n",
       "      <td>-12.531164</td>\n",
       "      <td>-11.790744</td>\n",
       "      <td>-3.735406</td>\n",
       "      <td>-6.268928</td>\n",
       "      <td>-9.658600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032486</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1060_ITS_NEU_XX</td>\n",
       "      <td>-565.523743</td>\n",
       "      <td>-29.746906</td>\n",
       "      <td>5.289134</td>\n",
       "      <td>20.724148</td>\n",
       "      <td>-6.095077</td>\n",
       "      <td>-11.757398</td>\n",
       "      <td>0.216888</td>\n",
       "      <td>-9.311358</td>\n",
       "      <td>-4.887557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1075_ITS_NEU_XX</td>\n",
       "      <td>-556.091248</td>\n",
       "      <td>-15.240954</td>\n",
       "      <td>11.779830</td>\n",
       "      <td>20.665905</td>\n",
       "      <td>-9.193678</td>\n",
       "      <td>-11.914318</td>\n",
       "      <td>0.438259</td>\n",
       "      <td>-7.635978</td>\n",
       "      <td>-7.933719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1073_IOM_DIS_XX</td>\n",
       "      <td>-622.589111</td>\n",
       "      <td>-13.248747</td>\n",
       "      <td>4.246189</td>\n",
       "      <td>30.263844</td>\n",
       "      <td>-10.529772</td>\n",
       "      <td>-10.335563</td>\n",
       "      <td>1.289759</td>\n",
       "      <td>-11.116067</td>\n",
       "      <td>-5.185853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040066</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          clipName      mfcc_0     mfcc_1     mfcc_2     mfcc_3     mfcc_4  \\\n",
       "0  1022_ITS_ANG_XX -625.058655  -4.994524  -5.040599  31.118151 -11.813456   \n",
       "1  1037_ITS_ANG_XX -648.157227 -10.045857   7.429339  20.802429 -12.531164   \n",
       "2  1060_ITS_NEU_XX -565.523743 -29.746906   5.289134  20.724148  -6.095077   \n",
       "3  1075_ITS_NEU_XX -556.091248 -15.240954  11.779830  20.665905  -9.193678   \n",
       "4  1073_IOM_DIS_XX -622.589111 -13.248747   4.246189  30.263844 -10.529772   \n",
       "\n",
       "      mfcc_5    mfcc_6     mfcc_7    mfcc_8  ...  tonnets_172         N  \\\n",
       "0 -14.570557  0.724647  -9.413414 -3.972650  ...     0.009466  0.000000   \n",
       "1 -11.790744 -3.735406  -6.268928 -9.658600  ...     0.032486  0.500000   \n",
       "2 -11.757398  0.216888  -9.311358 -4.887557  ...     0.003219  0.900000   \n",
       "3 -11.914318  0.438259  -7.635978 -7.933719  ...     0.001605  0.909091   \n",
       "4 -10.335563  1.289759 -11.116067 -5.185853  ...     0.040066  0.300000   \n",
       "\n",
       "          A         D    F    S    H       low    medium      high  \n",
       "0  0.454545  0.545455  0.0  0.0  0.0  0.000000  0.272727  0.727273  \n",
       "1  0.200000  0.200000  0.1  0.0  0.0  0.000000  0.300000  0.700000  \n",
       "2  0.000000  0.000000  0.0  0.1  0.0  0.000000  0.200000  0.800000  \n",
       "3  0.000000  0.090909  0.0  0.0  0.0  0.181818  0.090909  0.727273  \n",
       "4  0.000000  0.600000  0.0  0.1  0.0  0.200000  0.200000  0.600000  \n",
       "\n",
       "[5 rows x 183 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut corresponding columns of df into features and labels\n",
    "# Turn them into tensors\n",
    "features = df.iloc[:, 1:174].values\n",
    "features = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "emotionLabels = df.iloc[:,174:180].values\n",
    "emotionLabels = torch.tensor(emotionLabels, dtype=torch.float32)\n",
    "\n",
    "strengthLabels = df.iloc[:,180:183].values\n",
    "strengthLabels = torch.tensor(strengthLabels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5953 744 745\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "# train, validate, test = 8:1:1\n",
    "train_size = int(0.8 * len(df))\n",
    "val_size = int(0.1 * len(df))\n",
    "test_size = len(df) - train_size - val_size\n",
    "\n",
    "print(train_size, val_size, test_size)\n",
    "\n",
    "train_dataset = voiceDataset(features[:train_size], \n",
    "                             emotionLabels[:train_size], \n",
    "                             strengthLabels[:train_size])\n",
    "\n",
    "validate_dataset = voiceDataset(features[train_size:train_size + val_size],\n",
    "                                emotionLabels[train_size:train_size + val_size], \n",
    "                                strengthLabels[train_size:train_size + val_size])\n",
    "\n",
    "test_dataset = voiceDataset(features[train_size + val_size:],\n",
    "                            emotionLabels[train_size + val_size:], \n",
    "                            strengthLabels[train_size + val_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Define the trainer & validator function\n",
    "def train_validate_model(hidden_size, num_layers,dropout_rate, trainDataLoader, \n",
    "                         validationDataLoader,num_epochs, learning_rate,\n",
    "                         fineTuning= False):\n",
    "\n",
    "    set_seed(42)\n",
    "\n",
    "    #Get the GPU as a device if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    #Instantiate the model\n",
    "    model = baseLineClassifier(hidden_size = hidden_size,\n",
    "                           num_layers = num_layers,\n",
    "                           dropout_rate = dropout_rate)\n",
    "\n",
    "    # Moving the model to GPU if available\n",
    "    model.to(device)\n",
    "\n",
    "    #Prepare the optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #Prepare the error function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    #Prepare the scheduler\n",
    "    #Reduce the learning rate by 0.1 if the validation loss does not decrease for 3 epochs\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    #Prepare the DataLoader\n",
    "    train_data_loader = trainDataLoader\n",
    "    validation_data_loader = validationDataLoader\n",
    "\n",
    "    #Placeholder for minimum validation loss\n",
    "    min_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        #set the model to training mode\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0 #Placeholder for training loss per epoch\n",
    "        for batch in train_data_loader:\n",
    "            feature = batch['feature'].to(device)\n",
    "            emotionLabel = batch['emotionLabel'].to(device)\n",
    "            strengthLabel = batch['strengthLabel'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            emotionOutput, strengthOutput = model(feature)\n",
    "            #Calculate the loss for emotion head\n",
    "            emo_loss = criterion(emotionOutput, emotionLabel)\n",
    "            #Calculate the loss for strength head\n",
    "            strength_loss = criterion(strengthOutput, strengthLabel)\n",
    "            #Combine two losses to make a total loss. \n",
    "            #Put more weight on the emotion loss (7:3). Detecting emotion is more critical\n",
    "            loss = 0.7*emo_loss + 0.3*strength_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        #Validate the model\n",
    "        model.eval() #Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            total = 0 #Total output for accuracy calculation\n",
    "            emoCorrect = 0 #Amount of correct prediction for accuracy calculation\n",
    "            strengthCorrect = 0\n",
    "            total_val_loss = 0 #Placeholder for validation loss per epoch\n",
    "            \n",
    "            for batch in validation_data_loader:\n",
    "                feature = batch['feature'].to(device)\n",
    "                emotionLabel = batch['emotionLabel'].to(device)\n",
    "                strengthLabel = batch['strengthLabel'].to(device)\n",
    "                #Forward pass\n",
    "                emotionOutput, strengthOutput = model(feature)\n",
    "                emo_loss = criterion(emotionOutput, emotionLabel)\n",
    "                strength_loss = criterion(strengthOutput, strengthLabel )\n",
    "                total_val_loss += 0.7*emo_loss + 0.3*strength_loss\n",
    "                \n",
    "                # Get predicted emotion class & target emotion class\n",
    "                emo_predicted = torch.argmax(emotionOutput, dim=1)\n",
    "                emo_target = torch.argmax(emotionLabel, dim=1)\n",
    "                \n",
    "                # Get predicted strength class & target emotion class\n",
    "                strength_predicted = torch.argmax(strengthOutput,dim=1)\n",
    "                strength_target = torch.argmax(strengthOutput, dim=1 )\n",
    "                \n",
    "                \n",
    "                emoCorrect += (emo_predicted == emo_target).sum().item()\n",
    "                strengthCorrect += (strength_predicted ==strength_target).sum().item()\n",
    "\n",
    "            #Print out the validation loss and accuracy per epoch\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | Training Loss: {total_loss:.4f}, Validation Loss: {total_val_loss:.4f}, Accuracy (Emotion): {correct/total:.4f}\")\n",
    "\n",
    "            #pass the validation loss to the scheduler\n",
    "            scheduler.step(total_val_loss)\n",
    "\n",
    "        #If fineTuning = False, save the model with the lowest validation loss\n",
    "        #Save the first epoch model just in case\n",
    "\n",
    "            if epoch == 0:\n",
    "                min_val_loss = total_val_loss #Instantiate the min_val_loss at the first epoch\n",
    "                torch.save(model.state_dict(), 'meme_model.pth')\n",
    "            #Save the model if the validation loss is the lowest\n",
    "            elif total_val_loss < min_val_loss:\n",
    "                min_val_loss = total_val_loss\n",
    "                torch.save(model.state_dict(), 'meme_model_lowestVL.pth')\n",
    "                print(f\"Model saved after Epoch: {epoch+1}\")\n",
    "\n",
    "    #Return the minimum validation loss for hyperparameter tuning\n",
    "    return min_val_loss\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
